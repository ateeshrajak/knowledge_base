# To download <url>:
wget <url>
#
# To download multiples files with multiple URLs:
wget <url>...

# To download <url> and change its name:
wget <url> -O <outfile>

# To output downloaded page to stdin (e.g., to be processed by other tools)
wget -O- -o /dev/null | ...

# To download <url> into <dir>:
wget -P <dir> <url>

# To continue an aborted downloaded:
wget -c <url>

# To parse a file that contains a list of URLs to fetch each one:
wget -i url_list.txt

# To mirror a whole page locally:
wget -pk <url>

# To mirror a website and all directly connected webpages (depth = 1)
wget -r -l 1 "https://example.com/index.html"

# To mirror a website and all directly connected webpages (depth = 2)
wget -r -l 2 "https://example.com/index.html"

# To mirror a website infinitely
wget -r --mirror "https://example.com/index.html"

# To download all files with a certain extension (e.g, PDF)
wget -r -A.pdf http://url-to-webpage-with-pdfs/

# To mirror a whole site locally:
wget -mk <url>

# To download files according to a pattern:
wget http://example.com/files-{1..15}.tar.bz2

# To download all the files in a directory with a specific extension if directory indexing is enabled:
wget -r -l1 -A.extension http://example.com/directory

# To download only response headers (-S --spider) and display them on stdout (-O -).:
wget -S --spider -O - <url>

# To change the User-Agent to 'User-Agent: toto':
wget -U 'toto' <url>

# Download and immediately execute a script
wget http://server/file.sh -O- | sh
