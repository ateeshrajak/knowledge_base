# To spider a site and write all found words to a file
# the default depth is 2 and the url should be specified as
# http://example.com or https://example.com
cewl -w <file> <url>

# To get all words with a minimum length is 6
cewl -w <file> -m 6 <url>

# To spider a site and follow links to sites on other domains
cewl -o -w <file> <url>

# To spider a site using a given user-agent 
cewl -u <user-agent> <url>

# To spider a site for a given depth and minimum word length
cewl -d <depth> -m <min word length> <url>

# To get words that are at least 6 chars and going at maximum 1 level deep in crawling
cewl http://example.com/ -d 1 -m 6 -w words.txt

# To spider a site and include a count for each word
cewl -c <url>

# To spider a site inluding meta data and separate the meta_data words
cewl -a -meta_file <file> <url>

# To spider a site and store email adresses in a separate file
cewl -e -email_file <file> <url>
